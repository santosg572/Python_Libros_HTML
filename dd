Contents
1 Introduction: basic notions about Bayesian inference . . . . . . 1
1.1 Basic notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2 Simple dependence structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.3 Synthesis of conditional distributions . . . . . . . . . . . . . . . . . . . . . . . 11
1.4 Choice of the prior distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.5 Bayesian inference in the linear regression model . . . . . . . . . . . . 18
1.6 Markov chain Monte Carlo methods . . . . . . . . . . . . . . . . . . . . . . . 22
1.6.1 Gibbs sampler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
1.6.2 Metropolisâ€“Hastings algorithm . . . . . . . . . . . . . . . . . . . . . . 24
1.6.3 Adaptive rejection Metropolis sampling . . . . . . . . . . . . . . 25
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2 Dynamic linear models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.2 A simple example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.3 State space models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.4 Dynamic linear models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.5 Dynamic linear models in package dlm . . . . . . . . . . . . . . . . . . . . . 43
2.6 Examples of nonlinear and non-Gaussian state space models . . 48
2.7 State estimation and forecasting . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.7.1 Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
2.7.2 Kalman filter for dynamic linear models . . . . . . . . . . . . . . 53
2.7.3 Filtering with missing observations . . . . . . . . . . . . . . . . . . 59
2.7.4 Smoothing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
2.8 Forecasting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
2.9 The innovation process and model checking . . . . . . . . . . . . . . . . . 73
2.10 Controllability and observability of time-invariant DLMs . . . . . 77
2.11 Filter stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
XII Contents
3 Model specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
3.1 Classical tools for time series analysis . . . . . . . . . . . . . . . . . . . . . . 85
3.1.1 Empirical methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
3.1.2 ARIMA models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
3.2 Univariate DLMs for time series analysis . . . . . . . . . . . . . . . . . . . 88
3.2.1 Trend models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
3.2.2 Seasonal factor models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
3.2.3 Fourier form seasonal models . . . . . . . . . . . . . . . . . . . . . . . 102
3.2.4 General periodic components . . . . . . . . . . . . . . . . . . . . . . . 109
3.2.5 DLM representation of ARIMA models . . . . . . . . . . . . . . . 112
3.2.6 Example: estimating the output gap . . . . . . . . . . . . . . . . . 115
3.2.7 Regression models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
3.3 Models for multivariate time series . . . . . . . . . . . . . . . . . . . . . . . . . 125
3.3.1 DLMs for longitudinal data . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.3.2 Seemingly unrelated time series equations . . . . . . . . . . . . 127
3.3.3 Seemingly unrelated regression models . . . . . . . . . . . . . . . 132
3.3.4 Hierarchical DLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
3.3.5 Dynamic regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
3.3.6 Common factors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
3.3.7 Multivariate ARMA models . . . . . . . . . . . . . . . . . . . . . . . . 139
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
4 Models with unknown parameters . . . . . . . . . . . . . . . . . . . . . . . . . 143
4.1 Maximum likelihood estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
4.2 Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
4.3 Conjugate Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
4.3.1 Unknown covariance matrices: conjugate inference . . . . . 150
4.3.2 Specification of Wt by discount factors . . . . . . . . . . . . . . . 152
4.3.3 A discount factor model for time-varying Vt . . . . . . . . . . . 158
4.4 Simulation-based Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . 160
4.4.1 Drawing the states given y1:T : forward filtering
backward sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
4.4.2 General strategies for MCMC . . . . . . . . . . . . . . . . . . . . . . . 162
4.4.3 Illustration: Gibbs sampling for a local level model . . . . 165
4.5 Unknown variances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
4.5.1 Constant unknown variances: d Inverse Gamma prior . . 167
4.5.2 Multivariate extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
4.5.3 A model for outliers and structural breaks . . . . . . . . . . . . 177
4.6 Further examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
4.6.1 Estimating the output gap: Bayesian inference . . . . . . . . 186
4.6.2 Dynamic regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
4.6.3 Factor models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
Contents XIII
5 Sequential Monte Carlo methods . . . . . . . . . . . . . . . . . . . . . . . . . . 207
5.1 The basic particle filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
5.1.1 A simple example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
5.2 Auxiliary particle filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
5.3 Sequential Monte Carlo with unknown parameters . . . . . . . . . . . 219
5.3.1 A simple example with unknown parameters . . . . . . . . . . 226
5.4 Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
A Useful distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
B Matrix algebra: Singular Value Decomposition . . . . . . . . . . . . . 237
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241

